{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPlJww6JZ+qSrvD84BCJlj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARADHYA299/GenAI/blob/main/researchAssistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x3M9UxvGNiE",
        "outputId": "03dda7fd-12df-4184-e445-d175f92ca74f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/302.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q faiss-cpu langchain sentence-transformers transformers\n",
        "!pip install -q pypdf\n",
        "!pip install -U -q langchain-community\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "  reader = PdfReader(file_path)\n",
        "  text = \"\"\n",
        "\n",
        "  for page in reader.pages:\n",
        "    text += page.extract_text() + \"\\n\"\n",
        "  return text\n"
      ],
      "metadata": {
        "id": "L3bf9TmJKb66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "def split_text(text):\n",
        "  text_splitter = CharacterTextSplitter(\n",
        "      separator = \"\\n\",\n",
        "      chunk_size = 500,\n",
        "      chunk_overlap = 100,\n",
        "      length_function = len\n",
        "  )\n",
        "\n",
        "  return text_splitter.split_text(text)"
      ],
      "metadata": {
        "id": "oVpJKCVAgo68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "def embed_text(chunks):\n",
        "  embedder = HuggingFaceBgeEmbeddings(model_name = \"all-MiniLM-L6-v2\")\n",
        "  faiss_index = FAISS.from_texts(chunks, embedding=embedder)\n",
        "  return faiss_index\n"
      ],
      "metadata": {
        "id": "121rd-C7hRJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM , AutoTokenizer , pipeline\n",
        "\n",
        "def load_local_llm():\n",
        "  model_name = \"google/flan-t5-base\"\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  model = AutoModelForCausalLM.from_pretrained(model_name , device_map = \"auto\" , trust_remote_code = True)\n",
        "  pipe = pipeline(\"text2text-generation\" , model = model, tokenizer = tokenizer , max_length = 512)\n",
        "  llm = HuggingFacePipeline(pipeline = pipe)\n",
        "  return llm"
      ],
      "metadata": {
        "id": "cuimd4cHh6V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import retrieval_qa\n",
        "\n",
        "def build_qa_chain(llm , faiss_index):\n",
        "  retriver = faiss_index.as_retriver()\n",
        "  qa_chain = retrieval_qa.from_chain_type(\n",
        "      llm = llm,\n",
        "      retriver = retriver,\n",
        "      return_source_documents = True\n",
        "  )\n",
        "  return qa_chain"
      ],
      "metadata": {
        "id": "hInnZIh2jLl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def process_pdf_and_create_qa(pdf_file):\n",
        "    file_path = pdf_file.name\n",
        "\n",
        "    text = extract_text_from_pdf(file_path)\n",
        "\n",
        "    chunks = split_text(text)\n",
        "\n",
        "    vectorstore = embed_text(chunks)\n",
        "\n",
        "    llm  = load_local_llm()\n",
        "\n",
        "    qa_chain = build_qa_chain(faiss_index , llm)\n",
        "\n",
        "    return qa_chain"
      ],
      "metadata": {
        "id": "b7yD6uBfj0-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def handle_question(pdf_file, user_question):\n",
        "    if pdf_file is None or user_question.strip() == \"\":\n",
        "        return \"Please upload a PDF and enter a question.\"\n",
        "\n",
        "    try:\n",
        "        # Always reprocess the uploaded PDF (safe in stateless Gradio mode)\n",
        "        qa_chain = process_pdf_and_create_qa(pdf_file)\n",
        "        result = qa_chain.run(user_question)\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error: {str(e)}\"\n",
        "gr.Interface(\n",
        "    fn=handle_question,\n",
        "    inputs=[\n",
        "        gr.File(type=\"filepath\", label=\"Upload Research Paper (PDF)\"),\n",
        "        gr.Textbox(lines=2, label=\"Ask a question\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Answer\"),\n",
        "    title=\"üß† Research Paper Explorer (RAG Assistant)\",\n",
        "    description=\"Upload a research paper and ask anything about it.\"\n",
        ").launch(share=True)  # share=True gives you a public link (especially for Colab)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "GgnhQ6Jkkr9I",
        "outputId": "2d87a9b3-06d8-4f37-8d15-1ec56c7a76cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2de8c538dbfa1f4c50.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2de8c538dbfa1f4c50.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}